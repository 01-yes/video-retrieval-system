import open_clip
import torch

print("=== CLIP æµ‹è¯• ===")

try:
    print("1. å¯¼å…¥open_clip...")
    print("âœ… open_clip å¯¼å…¥æˆåŠŸ")
    print("ç‰ˆæœ¬:", open_clip.__version__)

    print("2. åŠ è½½CLIPæ¨¡å‹...")
    model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')
    print("âœ… CLIPæ¨¡å‹åŠ è½½æˆåŠŸ")
    
    print("3. æ£€æŸ¥è®¾å¤‡...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print("è®¾å¤‡:", device)
    
    print("4. æµ‹è¯•å›¾åƒç¼–ç å™¨...")
    # åˆ›å»ºä¸€ä¸ªéšæœºå›¾åƒè¿›è¡Œæµ‹è¯•
    import numpy as np
    from PIL import Image
    random_image = Image.fromarray(np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8))
    image_tensor = preprocess(random_image).unsqueeze(0)
    
    with torch.no_grad():
        features = model.encode_image(image_tensor)
        print("âœ… å›¾åƒç¼–ç å™¨å·¥ä½œæ­£å¸¸")
        print("ç‰¹å¾ç»´åº¦:", features.shape)
    
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼CLIPå®Œå…¨å¯ç”¨")

except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    print("é”™è¯¯ç±»å‹:", type(e).__name__)